{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import statistics\n",
    "import re\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_SIZE = 0.2\n",
    "VAL_TEST_SIZE = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predictions):\n",
    "  f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "  precision = precision_score(true_labels, predictions, average=\"macro\")\n",
    "  recall = recall_score(true_labels, predictions, average=\"macro\")\n",
    "  accuracy = accuracy_score(true_labels,predictions)\n",
    "  return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rayenebech/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rayenebech/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv(\"../datasets/bbc/bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_X, test_X):\n",
    "    train_Y = train_X.pop(\"category\")\n",
    "    test_Y = test_X.pop(\"category\")\n",
    "    return train_X, train_Y, test_X, test_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub('<br \\/>','',text) \n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text) \n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../datasets/movies/sampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>why and she screaming ahaha this song is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the_trini_bajan work as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>desi_f pack me in your luggage I wanna go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>elm8 Thanks  I enjoy talking to you too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>watchin the season finale of The Office lets h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0</td>\n",
       "      <td>So sleepy this morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>0</td>\n",
       "      <td>bakespace do you archive your newsletters some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>4</td>\n",
       "      <td>santyadh hope that will soon change though  bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>0</td>\n",
       "      <td>I think I should do my homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0</td>\n",
       "      <td>This is officially the only day since starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         4    why and she screaming ahaha this song is funny \n",
       "1         0                     the_trini_bajan work as usual \n",
       "2         0         desi_f pack me in your luggage I wanna go \n",
       "3         4            elm8 Thanks  I enjoy talking to you too\n",
       "4         4  watchin the season finale of The Office lets h...\n",
       "...     ...                                                ...\n",
       "4795      0                           So sleepy this morning  \n",
       "4796      0  bakespace do you archive your newsletters some...\n",
       "4797      4  santyadh hope that will soon change though  bo...\n",
       "4798      0                   I think I should do my homework \n",
       "4799      0  This is officially the only day since starting...\n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(\"../datasets/twitter_sampled.csv\")\n",
    "twitter_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model on BBC News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, test_X, test_Y):\n",
    "    tf_idf = TfidfVectorizer(analyzer=\"char\", ngram_range =(2,6))\n",
    "    classifier_tfidf = LogisticRegression()\n",
    "    # Train\n",
    "    model_tfidf = Pipeline([(\"vectorizer\", tf_idf), (\"classifier\", classifier_tfidf)])\n",
    "    start_time = datetime.now()\n",
    "    model_tfidf.fit(train_X[\"text\"], train_Y)\n",
    "    end_time = datetime.now()\n",
    "    training_time_tfidf = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Eval    \n",
    "    predicted_test_tfidf = model_tfidf.predict(test_X[\"text\"])\n",
    "    test_f1, test_precision, test_recall, test_accuracy = get_metrics(predicted_test_tfidf, test_Y)\n",
    "    print('Testing: Accuracy: {:.3%}, Recall: {:.3%}, Precision: {:.3%}, f1: {:.3%}'.format(test_accuracy,test_recall, test_precision, test_f1))\n",
    "    print('Training time: {:.2f}s'.format(training_time_tfidf))\n",
    "    return test_precision, test_recall, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 96.861%, Recall: 96.907%, Precision: 96.720%, f1: 96.802%\n",
      "Training time: 66.43s\n",
      "Testing: Accuracy: 98.206%, Recall: 98.222%, Precision: 98.160%, f1: 98.138%\n",
      "Training time: 80.97s\n",
      "Testing: Accuracy: 98.206%, Recall: 98.281%, Precision: 98.135%, f1: 98.197%\n",
      "Training time: 59.63s\n",
      "Testing: Accuracy: 97.309%, Recall: 97.278%, Precision: 97.124%, f1: 97.173%\n",
      "Training time: 61.58s\n",
      "Testing: Accuracy: 95.964%, Recall: 96.084%, Precision: 95.716%, f1: 95.875%\n",
      "Training time: 79.47s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(bbc_df, bbc_df[\"category\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.9671996630820161, 0.9816020671834625, 0.9813492063492063, 0.9712446468260423, 0.9571557754484583]\n",
      "Precision avg: 0.9717 (+/- 0.0206)\n",
      "Recall values: [0.9690676691729323, 0.9822222222222223, 0.9828059916333048, 0.9727815494246232, 0.9608412055780476]\n",
      "Recall avg: 0.9735 (+/- 0.0185)\n",
      "F1 values: [0.968021087823068, 0.9813801505907396, 0.9819736232031321, 0.9717303061575506, 0.9587532855118232]\n",
      "F1 avg: 0.9724 (+/- 0.0194)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with movies dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 85.600%, Recall: 85.653%, Precision: 85.608%, f1: 85.596%\n",
      "Training time: 30.57s\n",
      "Testing: Accuracy: 85.800%, Recall: 85.800%, Precision: 85.846%, f1: 85.795%\n",
      "Training time: 31.71s\n",
      "Testing: Accuracy: 84.000%, Recall: 84.278%, Precision: 83.964%, f1: 83.957%\n",
      "Training time: 38.96s\n",
      "Testing: Accuracy: 82.000%, Recall: 82.109%, Precision: 82.200%, f1: 81.995%\n",
      "Training time: 30.05s\n",
      "Testing: Accuracy: 85.800%, Recall: 86.344%, Precision: 85.653%, f1: 85.704%\n",
      "Training time: 29.20s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(movies_df, movies_df[\"sentiment\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.8560776972431559, 0.8584645700828273, 0.8396377368151562, 0.8219991971095946, 0.8565253586065573]\n",
      "Precision avg: 0.8465 (+/- 0.0313)\n",
      "Recall values: [0.8565340681523255, 0.858, 0.8427750145339448, 0.821091735920962, 0.8634434924520604]\n",
      "Recall avg: 0.8484 (+/- 0.0341)\n",
      "F1 values: [0.8559631265603994, 0.8579539770885767, 0.8395661869695656, 0.8199539082004994, 0.8570387284098276]\n",
      "F1 avg: 0.8461 (+/- 0.0329)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Twitter Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 72.083%, Recall: 71.988%, Precision: 71.988%, f1: 71.988%\n",
      "Training time: 1.82s\n",
      "Testing: Accuracy: 74.375%, Recall: 74.319%, Precision: 74.178%, f1: 74.222%\n",
      "Training time: 2.76s\n",
      "Testing: Accuracy: 75.625%, Recall: 75.622%, Precision: 75.619%, f1: 75.620%\n",
      "Training time: 1.83s\n",
      "Testing: Accuracy: 74.375%, Recall: 74.599%, Precision: 74.333%, f1: 74.294%\n",
      "Training time: 2.01s\n",
      "Testing: Accuracy: 72.917%, Recall: 72.988%, Precision: 72.876%, f1: 72.870%\n",
      "Training time: 1.79s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(twitter_df, twitter_df[\"label\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.7198801477248973, 0.7417775764755069, 0.7561858623743294, 0.7433328703382179, 0.7287597020367766]\n",
      "Precision avg: 0.7380 (+/- 0.0281)\n",
      "Recall values: [0.7198801477248973, 0.7431883092989434, 0.7562170047235344, 0.7459850811759543, 0.7298773359389995]\n",
      "Recall avg: 0.7390 (+/- 0.0285)\n",
      "F1 values: [0.7198801477248973, 0.7422183023258859, 0.7561981497801182, 0.7429366354480975, 0.7286956521739131]\n",
      "F1 avg: 0.7380 (+/- 0.0281)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
