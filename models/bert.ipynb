{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup, get_constant_schedule_with_warmup\n",
    "\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import json\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 32\n",
    "TEST_BATCH_SIZE = 128\n",
    "TRAIN_VAL_SIZE = 0.2\n",
    "VAL_TEST_SIZE = 0.5\n",
    "EPOCH = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv(\"../datasets/bbc/bbc-text.csv\")\n",
    "bbc_df[\"category\"] = pd.Categorical(bbc_df['category']).codes\n",
    "labels = bbc_df[\"category\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub('<br \\/>','',text) \n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text) \n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production The filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically theres a family where a little boy J...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Matteis Love in the Time of Money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>Im going to have to disagree with the previous...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production The filming tech...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically theres a family where a little boy J...  negative\n",
       "4      Petter Matteis Love in the Time of Money is a ...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot bad dialogue bad acting idiotic direc...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  Im going to have to disagree with the previous...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(\"../datasets/IMDB_Dataset.csv\")\n",
    "movies_df[\"review\"] = movies_df[\"review\"].apply(lambda x: clean_text(x))\n",
    "movies_df = movies_df.rename(columns={\"review\": \"text\"})\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_imdb = movies_df.sample(frac=0.1, ignore_index= True)\n",
    "sampled_imdb.to_csv(\"../datasets/movies/sampled.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../datasets/movies/sampled.csv\")\n",
    "labels = movies_df[\"sentiment\"].unique()\n",
    "movies_df[\"sentiment\"] = pd.Categorical(movies_df['sentiment']).codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A female vampire kills young women and paints ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personally I think this show looks pretty chea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I grew up watching Inspector Gadget It was and...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is awful Im SORRY I bought this to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a great example of a good dumb movie N...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>After watching this on the MST3K episode I hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Upon completing this infernal piece of trash a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Maybe Im biased because the F16 is my favorite...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>The Best Movie of the 90s The Welsh Trainspott...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>This was a excellent back when it came out It ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment\n",
       "0     A female vampire kills young women and paints ...          0\n",
       "1     Personally I think this show looks pretty chea...          0\n",
       "2     I grew up watching Inspector Gadget It was and...          0\n",
       "3     This movie is awful Im SORRY I bought this to ...          0\n",
       "4     This is a great example of a good dumb movie N...          1\n",
       "...                                                 ...        ...\n",
       "4995  After watching this on the MST3K episode I hav...          0\n",
       "4996  Upon completing this infernal piece of trash a...          0\n",
       "4997  Maybe Im biased because the F16 is my favorite...          1\n",
       "4998  The Best Movie of the 90s The Welsh Trainspott...          0\n",
       "4999  This was a excellent back when it came out It ...          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>why and she screaming ahaha this song is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the_trini_bajan work as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>desi_f pack me in your luggage I wanna go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>elm8 Thanks  I enjoy talking to you too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>watchin the season finale of The Office lets h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0</td>\n",
       "      <td>So sleepy this morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>0</td>\n",
       "      <td>bakespace do you archive your newsletters some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>1</td>\n",
       "      <td>santyadh hope that will soon change though  bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>0</td>\n",
       "      <td>I think I should do my homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0</td>\n",
       "      <td>This is officially the only day since starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         1    why and she screaming ahaha this song is funny \n",
       "1         0                     the_trini_bajan work as usual \n",
       "2         0         desi_f pack me in your luggage I wanna go \n",
       "3         1            elm8 Thanks  I enjoy talking to you too\n",
       "4         1  watchin the season finale of The Office lets h...\n",
       "...     ...                                                ...\n",
       "4795      0                           So sleepy this morning  \n",
       "4796      0  bakespace do you archive your newsletters some...\n",
       "4797      1  santyadh hope that will soon change though  bo...\n",
       "4798      0                   I think I should do my homework \n",
       "4799      0  This is officially the only day since starting...\n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(\"../datasets/twitter_sampled.csv\")\n",
    "labels = twitter_df[\"label\"].unique()\n",
    "twitter_df[\"label\"] = twitter_df[\"label\"].apply(lambda x: 1 if x==4 else 0)\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "  def __init__(self, ids, texts, targets, tokenizer, max_len):\n",
    "    self.ids = ids\n",
    "    self.texts = texts\n",
    "    self.targets = targets\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_len = max_len\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    id = self.ids[idx]\n",
    "    text = self.texts[idx]\n",
    "    label = self.targets[idx]\n",
    "\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "      text,\n",
    "      add_special_tokens=True,\n",
    "      max_length=self.max_len,\n",
    "      return_token_type_ids=False,\n",
    "      padding='max_length',\n",
    "      return_attention_mask=True,\n",
    "      truncation=True,\n",
    "      return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    return {\n",
    "      'id': torch.tensor(id, dtype=torch.long),\n",
    "      'text': text,\n",
    "      'input_ids': encoding['input_ids'].flatten(),\n",
    "      'attention_mask': encoding['attention_mask'],\n",
    "      'label': torch.tensor(label, dtype=torch.int)\n",
    "    }\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\")\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTClassifier(nn.Module):\n",
    "  def __init__(self, n_classes, bert_model, dropout=0.3):\n",
    "    super(BERTClassifier, self).__init__()\n",
    "    self.bert = bert_model\n",
    "    self.drop = nn.Dropout(dropout)\n",
    "    self.out = nn.Linear(bert_model.config.hidden_size, n_classes)\n",
    "\n",
    "  def forward(self, input_ids, attention_mask):\n",
    "    pooled_output = self.bert(\n",
    "      input_ids=input_ids,\n",
    "      attention_mask = attention_mask\n",
    "    )\n",
    "    \n",
    "    output = self.drop(pooled_output[0][:, 0, :])\n",
    "    return self.out(output)\n",
    "\n",
    "  def save_pretrained(self, path):\n",
    "    self.bert.save_pretrained(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(train_X,train_Y, val_X, val_Y, test_X, test_Y):\n",
    "    train_dataset = TextDataset(\n",
    "    texts=train_X.text.to_numpy(),\n",
    "    targets=train_Y.to_numpy(),\n",
    "    ids=train_X.index.to_numpy(),\n",
    "    tokenizer=bert_tokenizer,\n",
    "    max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    validation_dataset = TextDataset(\n",
    "    texts=val_X.text.to_numpy(),\n",
    "    targets=val_Y.to_numpy(),\n",
    "    ids=val_X.index.to_numpy(),\n",
    "    tokenizer=bert_tokenizer,\n",
    "    max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    test_dataset = TextDataset(\n",
    "    texts=test_X.text.to_numpy(),\n",
    "    targets=test_Y.to_numpy(),\n",
    "    ids=test_X.index.to_numpy(),\n",
    "    tokenizer=bert_tokenizer,\n",
    "    max_len=MAX_LEN\n",
    "    )\n",
    "\n",
    "    train_dataloader =  DataLoader(train_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "    val_dataloader = DataLoader(validation_dataset, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "    test_dataloader =  DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "\n",
    "    return train_dataloader, val_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_model(model, data_loader, loss_fn, device):\n",
    "  model = model.eval()\n",
    "  losses = []\n",
    "  predictions = []\n",
    "  all_predictions , true_labels, ids = [], [], []\n",
    "  correct_predictions = 0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    \n",
    "    for d in data_loader:\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      labels = d[\"label\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, labels.long())\n",
    "      losses.append(loss.item())\n",
    "      correct_predictions += torch.sum(preds == labels)\n",
    "      all_predictions.append(preds.cpu().data)\n",
    "      true_labels.append(labels.cpu().data) \n",
    "      ids.append(d[\"id\"].cpu().data)\n",
    "  \n",
    "  all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "  true_labels = np.concatenate(true_labels, axis=0)\n",
    "  predictions = {\"id\":ids,\"preds\":all_predictions,\"exact\":true_labels}\n",
    "\n",
    "  \n",
    "  f1 = f1_score(true_labels, all_predictions, average=\"macro\")\n",
    "  precision = precision_score(true_labels, all_predictions, average=\"macro\")\n",
    "  recall = recall_score(true_labels, all_predictions, average=\"macro\")\n",
    "  accuracy = accuracy_score(true_labels,all_predictions)\n",
    "\n",
    "  \n",
    "  \n",
    "  return accuracy,precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(\n",
    "  model,\n",
    "  epochs,\n",
    "  train_data_loader,\n",
    "  val_data_loader,\n",
    "  loss_fn,\n",
    "  optimizer,\n",
    "  device,\n",
    "  scheduler,\n",
    "  output_dir):\n",
    "\n",
    "  model = model.train()\n",
    "  results = []\n",
    "  for e in range(epochs):\n",
    "    all_predictions , true_labels = [], []\n",
    "    correct_predictions = 0\n",
    "    losses = []\n",
    "\n",
    "    for d in tqdm(train_data_loader):\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      labels = d[\"label\"].to(device)\n",
    "      \n",
    "\n",
    "      outputs = model(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "      )\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "      loss = loss_fn(outputs, labels.long())\n",
    "\n",
    "      all_predictions.append(preds.cpu().data)\n",
    "      true_labels.append(labels.cpu().data) \n",
    "\n",
    "      correct_predictions += torch.sum(preds == labels)\n",
    "      losses.append(loss.item())\n",
    "      loss.backward()\n",
    "        \n",
    "      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "      \n",
    "      optimizer.step()\n",
    "      scheduler.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "    all_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    true_labels = np.concatenate(true_labels, axis=0)\n",
    "    train_f1 = f1_score(true_labels, all_predictions,average=\"macro\")\n",
    "    train_precision = precision_score(true_labels, all_predictions ,average=\"macro\")\n",
    "    train_recall = recall_score(true_labels, all_predictions, average=\"macro\")\n",
    "    train_accuracy = accuracy_score(true_labels,all_predictions)\n",
    "    print(f\"Epoch: {e + 1} Train Accuracy: {train_accuracy} Train Precision: {train_precision} Train Recall: {train_recall} Train F1: {train_f1}\" )\n",
    "\n",
    "    val_acc, val_precision, val_recall, val_f1 = eval_model(model, val_data_loader, loss_fn, device)\n",
    "    print(f\"Validation Accuracy: {val_acc} Validation Precision: {val_precision} Validation Recall: {val_recall} Validation F1: {val_f1}\" )\n",
    "\n",
    "    results.append({\n",
    "        \"epoch\": e,\n",
    "        \"train_loss\": losses,\n",
    "        \"train_f1\": val_f1,\n",
    "        \"train_accuracy\": val_precision,\n",
    "        \"train_recall\": val_recall,\n",
    "        \"val_accuracy\": val_acc,\n",
    "        \"val_f1\": val_f1\n",
    "        })\n",
    "    \n",
    "    with open(os.path.join(output_dir,\"results.json\"), \"w\") as f:\n",
    "      json.dump(results, f)\n",
    "\n",
    "  model.save_pretrained(output_dir)\n",
    "\n",
    "  return val_acc, val_precision, val_recall, val_f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with BBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 56/56 [03:59<00:00,  4.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.9123595505617977 Train Precision: 0.9115121535571087 Train Recall: 0.9098170516937341 Train F1: 0.9092758628771238\n",
      "Validation Accuracy: 0.990990990990991 Validation Precision: 0.9927272727272728 Validation Recall: 0.9908902691511386 Validation F1: 0.9916888555442771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:59<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Accuracy: 0.9932584269662922 Train Precision: 0.9933964384005618 Train Recall: 0.9929822341309359 Train F1: 0.9931822550559796\n",
      "Validation Accuracy: 0.990990990990991 Validation Precision: 0.9927272727272728 Validation Recall: 0.9908902691511386 Validation F1: 0.9916888555442771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:57<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Accuracy: 0.998314606741573 Train Precision: 0.9981218850424307 Train Recall: 0.9983792289535799 Train F1: 0.9982463511713282\n",
      "Validation Accuracy: 0.990990990990991 Validation Precision: 0.9927272727272728 Validation Recall: 0.9908902691511386 Validation F1: 0.9916888555442771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 621.72s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [04:06<00:00,  4.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.9179775280898876 Train Precision: 0.9241977329589266 Train Recall: 0.9197134229426929 Train F1: 0.9213108706798018\n",
      "Validation Accuracy: 0.990990990990991 Validation Precision: 0.992080745341615 Validation Recall: 0.992080745341615 Validation F1: 0.992080745341615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:58<00:00,  3.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Accuracy: 0.9971910112359551 Train Precision: 0.9971450576039078 Train Recall: 0.9969811576722624 Train F1: 0.9970622830804325\n",
      "Validation Accuracy: 0.9954954954954955 Validation Precision: 0.9957446808510639 Validation Recall: 0.9964285714285716 Validation F1: 0.9960476605637896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:57<00:00,  3.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Accuracy: 0.998314606741573 Train Precision: 0.9981776288227902 Train Recall: 0.9983850622148163 Train F1: 0.9982773861090708\n",
      "Validation Accuracy: 0.9954954954954955 Validation Precision: 0.9957446808510639 Validation Recall: 0.9964285714285716 Validation F1: 0.9960476605637896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 627.64s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:56<00:00,  4.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.9174157303370787 Train Precision: 0.9155562190259767 Train Recall: 0.9184504679172549 Train F1: 0.9166165477132685\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:59<00:00,  3.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Accuracy: 0.9977528089887641 Train Precision: 0.9977077797531431 Train Recall: 0.9979593044765076 Train F1: 0.9978306580306017\n",
      "Validation Accuracy: 0.9954954954954955 Validation Precision: 0.9953488372093023 Validation Recall: 0.9959183673469388 Validation F1: 0.9955852031534264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:04<00:00,  3.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Accuracy: 0.998876404494382 Train Precision: 0.9987450903377848 Train Recall: 0.9989004809470957 Train F1: 0.9988210251559921\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 625.78s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:55<00:00,  4.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.9219101123595506 Train Precision: 0.9229862496851121 Train Recall: 0.9209235032645402 Train F1: 0.9218024708036847\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:07<00:00,  3.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Accuracy: 0.998314606741573 Train Precision: 0.9984015188633023 Train Recall: 0.998244230164347 Train F1: 0.998320921779986\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:02<00:00,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Accuracy: 1.0 Train Precision: 1.0 Train Recall: 1.0 Train F1: 1.0\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 629.77s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [03:37<00:00,  3.89s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.9393258426966292 Train Precision: 0.9386318510746371 Train Recall: 0.9405485565114781 Train F1: 0.9391583724860861\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:54<00:00,  3.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Train Accuracy: 0.999438202247191 Train Precision: 0.9993975903614458 Train Recall: 0.9993527508090615 Train F1: 0.9993741917662214\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 56/56 [02:58<00:00,  3.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Train Accuracy: 1.0 Train Precision: 1.0 Train Recall: 1.0 Train F1: 1.0\n",
      "Validation Accuracy: 1.0 Validation Precision: 1.0 Validation Recall: 1.0 Validation F1: 1.0\n",
      "Training time: 595.62s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "accuracies = []\n",
    "for i in range(5):\n",
    "  train_X, val_X, train_Y, val_Y = train_test_split(bbc_df, bbc_df[\"category\"], test_size = TRAIN_VAL_SIZE)\n",
    "  val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "  train_dataloader, val_dataloader, test_dataloader = get_data_loaders(train_X,train_Y, val_X, val_Y, test_X, test_Y)\n",
    "  model = BERTClassifier(len(labels), bert_model, 0.2) \n",
    "  model = model.to(device)\n",
    "\n",
    "  optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "  total_steps = len(train_dataloader) * EPOCH\n",
    "  warmup_step = int(len(train_dataloader)/10) \n",
    "\n",
    "  scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_step,\n",
    "    num_training_steps=total_steps\n",
    "  )\n",
    "\n",
    "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "  ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "  output_dir = os.path.join(\"../model_outputs\", ts)\n",
    "  os.mkdir(output_dir)\n",
    "  start_time = datetime.now()\n",
    "  acuuracy, precision, recall, f1 = train(model=model, epochs=EPOCH, train_data_loader=train_dataloader, val_data_loader=val_dataloader, \n",
    "      loss_fn=loss_fn, optimizer=optimizer, device=device, scheduler=scheduler, output_dir=output_dir)\n",
    "  end_time = datetime.now()\n",
    "  training_time = (end_time - start_time).total_seconds()\n",
    "  print('Training time: {:.2f}s'.format(training_time))\n",
    "  precisions.append(precision)\n",
    "  recalls.append(recall)\n",
    "  f1s.append(f1)\n",
    "  accuracies.append(acuuracy)\n",
    "\n",
    "  del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.9927272727272728, 0.9957446808510639, 1.0, 1.0, 1.0]\n",
      "Precision avg: 0.9977 (+/- 0.0067)\n",
      "Recall values: [0.9908902691511386, 0.9964285714285716, 1.0, 1.0, 1.0]\n",
      "Recall avg: 0.9975 (+/- 0.0080)\n",
      "F1 values: [0.9916888555442771, 0.9960476605637896, 1.0, 1.0, 1.0]\n",
      "F1 avg: 0.9975 (+/- 0.0074)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [17:19<00:00,  8.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.84775 Train Precision: 0.8478362887323115 Train Recall: 0.8476622662266227 Train F1: 0.8477046826246235\n",
      "Validation Accuracy: 0.866 Validation Precision: 0.8657540172062994 Validation Recall: 0.8658653846153846 Validation F1: 0.8658062241877271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1079.34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [16:47<00:00,  8.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.86675 Train Precision: 0.8668663099945957 Train Recall: 0.8667411167411168 Train F1: 0.8667373317175964\n",
      "Validation Accuracy: 0.882 Validation Precision: 0.8819658448895737 Validation Recall: 0.8815065967713493 Validation F1: 0.8817042606516291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1046.45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [16:52<00:00,  8.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.8815 Train Precision: 0.8815024703756176 Train Recall: 0.8815368086969849 Train F1: 0.8814976003264067\n",
      "Validation Accuracy: 0.934 Validation Precision: 0.9345510259742343 Validation Recall: 0.933625768442623 Validation F1: 0.9339045581820148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 1059.33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [15:04<00:00,  7.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.91275 Train Precision: 0.9128655971222697 Train Recall: 0.9126949720536306 Train F1: 0.9127322791984447\n",
      "Validation Accuracy: 0.96 Validation Precision: 0.9594247560349256 Validation Recall: 0.9603705609881626 Validation F1: 0.9598354861512757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 925.19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [10:10<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.93 Train Precision: 0.9311090920541913 Train Recall: 0.9296343446513025 Train F1: 0.9298987738294098\n",
      "Validation Accuracy: 0.952 Validation Precision: 0.9516967092180384 Validation Recall: 0.9520737031330252 Validation F1: 0.9518698560908697\n",
      "Training time: 631.43s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "accuracies = []\n",
    "for i in range(5):\n",
    "  train_X, val_X, train_Y, val_Y = train_test_split(movies_df, movies_df[\"sentiment\"], test_size = TRAIN_VAL_SIZE)\n",
    "  val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "  train_dataloader, val_dataloader, test_dataloader = get_data_loaders(train_X,train_Y, val_X, val_Y, test_X, test_Y)\n",
    "  model = BERTClassifier(len(labels), bert_model, 0.2) \n",
    "  model = model.to(device)\n",
    "\n",
    "  optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "  total_steps = len(train_dataloader) * EPOCH\n",
    "  warmup_step = int(len(train_dataloader)/10) \n",
    "\n",
    "  scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_step,\n",
    "    num_training_steps=total_steps\n",
    "  )\n",
    "\n",
    "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "  ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "  output_dir = os.path.join(\"../model_outputs\", ts)\n",
    "  os.mkdir(output_dir)\n",
    "  start_time = datetime.now()\n",
    "  acuuracy, precision, recall, f1 = train(model=model, epochs=EPOCH, train_data_loader=train_dataloader, val_data_loader=val_dataloader, \n",
    "      loss_fn=loss_fn, optimizer=optimizer, device=device, scheduler=scheduler, output_dir=output_dir)\n",
    "  end_time = datetime.now()\n",
    "  training_time = (end_time - start_time).total_seconds()\n",
    "  print('Training time: {:.2f}s'.format(training_time))\n",
    "  precisions.append(precision)\n",
    "  recalls.append(recall)\n",
    "  f1s.append(f1)\n",
    "  accuracies.append(acuuracy)\n",
    "\n",
    "  del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.8657540172062994, 0.8819658448895737, 0.9345510259742343, 0.9594247560349256, 0.9516967092180384]\n",
      "Precision avg: 0.9187 (+/- 0.0846)\n",
      "Recall values: [0.8658653846153846, 0.8815065967713493, 0.933625768442623, 0.9603705609881626, 0.9520737031330252]\n",
      "Recall avg: 0.9187 (+/- 0.0851)\n",
      "F1 values: [0.8658062241877271, 0.8817042606516291, 0.9339045581820148, 0.9598354861512757, 0.9518698560908697]\n",
      "F1 avg: 0.9186 (+/- 0.0848)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training with Twitter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "100%|██████████| 120/120 [10:09<00:00,  5.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.6755208333333333 Train Precision: 0.6755344546934346 Train Recall: 0.6755155984327239 Train F1: 0.6755101824902564\n",
      "Validation Accuracy: 0.775 Validation Precision: 0.7782281311693076 Validation Recall: 0.7768737286809576 Validation F1: 0.7749023013460704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 629.95s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [10:12<00:00,  5.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.775 Train Precision: 0.775012200411735 Train Recall: 0.7750145877228748 Train F1: 0.7749999389648272\n",
      "Validation Accuracy: 0.8125 Validation Precision: 0.8131123618928497 Validation Recall: 0.8132647385984426 Validation F1: 0.8124967447351517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 632.67s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [10:14<00:00,  5.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.7919270833333333 Train Precision: 0.7921214543937709 Train Recall: 0.7918146859549533 Train F1: 0.7918389802433063\n",
      "Validation Accuracy: 0.8229166666666666 Validation Precision: 0.8229166666666667 Validation Recall: 0.8235964439186485 Validation F1: 0.822823618306489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 635.88s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [10:15<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.81953125 Train Precision: 0.8195568946489438 Train Recall: 0.8195288952715102 Train F1: 0.8195268316776689\n",
      "Validation Accuracy: 0.8791666666666667 Validation Precision: 0.8791666666666667 Validation Recall: 0.8791666666666667 Validation F1: 0.8791666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayenebech/Library/Python/3.8/lib/python/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 635.22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120/120 [10:02<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Train Accuracy: 0.846875 Train Precision: 0.8469124334952705 Train Recall: 0.8469033990722404 Train F1: 0.846874833848561\n",
      "Validation Accuracy: 0.9020833333333333 Validation Precision: 0.9020833333333333 Validation Recall: 0.9022579244463742 Validation F1: 0.9020727075420509\n",
      "Training time: 623.03s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "accuracies = []\n",
    "for i in range(5):\n",
    "  train_X, val_X, train_Y, val_Y = train_test_split(twitter_df, twitter_df[\"label\"], test_size = TRAIN_VAL_SIZE)\n",
    "  val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "  train_dataloader, val_dataloader, test_dataloader = get_data_loaders(train_X,train_Y, val_X, val_Y, test_X, test_Y)\n",
    "  model = BERTClassifier(len(labels), bert_model, 0.2) \n",
    "  model = model.to(device)\n",
    "\n",
    "  optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "  total_steps = len(train_dataloader) * EPOCH\n",
    "  warmup_step = int(len(train_dataloader)/10) \n",
    "\n",
    "  scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=warmup_step,\n",
    "    num_training_steps=total_steps\n",
    "  )\n",
    "\n",
    "  loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "  ts = datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "  output_dir = os.path.join(\"../model_outputs\", ts)\n",
    "  os.mkdir(output_dir)\n",
    "  start_time = datetime.now()\n",
    "  acuuracy, precision, recall, f1 = train(model=model, epochs=EPOCH, train_data_loader=train_dataloader, val_data_loader=val_dataloader, \n",
    "      loss_fn=loss_fn, optimizer=optimizer, device=device, scheduler=scheduler, output_dir=output_dir)\n",
    "  end_time = datetime.now()\n",
    "  training_time = (end_time - start_time).total_seconds()\n",
    "  print('Training time: {:.2f}s'.format(training_time))\n",
    "  precisions.append(precision)\n",
    "  recalls.append(recall)\n",
    "  f1s.append(f1)\n",
    "  accuracies.append(acuuracy)\n",
    "\n",
    "  del model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.7782281311693076, 0.8131123618928497, 0.8229166666666667, 0.8791666666666667, 0.9020833333333333]\n",
      "Precision avg: 0.8391 (+/- 0.1011)\n",
      "Recall values: [0.7768737286809576, 0.8132647385984426, 0.8235964439186485, 0.8791666666666667, 0.9022579244463742]\n",
      "Recall avg: 0.8390 (+/- 0.1019)\n",
      "F1 values: [0.7749023013460704, 0.8124967447351517, 0.822823618306489, 0.8791666666666667, 0.9020727075420509]\n",
      "F1 avg: 0.8383 (+/- 0.1033)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd4a2e0defd57de5fbee3712486c1f066f8e1e168ee0000614ffba8faf61667"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
