{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import time\n",
    "import statistics\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_SIZE = 0.2\n",
    "VAL_TEST_SIZE = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(precision, recall):\n",
    "    return (precision * recall *2) / (precision + recall)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv(\"../datasets/bbc/bbc-text.csv\")\n",
    "bbc_df = bbc_df[[\"text\", \"category\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text=re.sub('<br \\/>','',text) \n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text) \n",
    "    text = re.sub('\\[[^]]*\\]', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"../datasets/twitter.csv\", encoding='latin-1', names = [\"label\",\"id\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "twitter_df = twitter_df.sample(frac=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tm/fb4f8v2142z_9s8x18s5_tbc0000gn/T/ipykernel_13183/893668531.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  twitter_df[\"text\"] = twitter_df[\"text\"].apply(lambda x: clean_text(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1203885</th>\n",
       "      <td>4</td>\n",
       "      <td>why and she screaming ahaha this song is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484270</th>\n",
       "      <td>0</td>\n",
       "      <td>the_trini_bajan work as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543432</th>\n",
       "      <td>0</td>\n",
       "      <td>desi_f pack me in your luggage I wanna go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502254</th>\n",
       "      <td>4</td>\n",
       "      <td>elm8 Thanks  I enjoy talking to you too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>943392</th>\n",
       "      <td>4</td>\n",
       "      <td>watchin the season finale of The Office lets h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>0</td>\n",
       "      <td>So sleepy this morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392307</th>\n",
       "      <td>0</td>\n",
       "      <td>bakespace do you archive your newsletters some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267790</th>\n",
       "      <td>4</td>\n",
       "      <td>santyadh hope that will soon change though  bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84846</th>\n",
       "      <td>0</td>\n",
       "      <td>I think I should do my homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>580395</th>\n",
       "      <td>0</td>\n",
       "      <td>This is officially the only day since starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "1203885      4    why and she screaming ahaha this song is funny \n",
       "484270       0                     the_trini_bajan work as usual \n",
       "543432       0         desi_f pack me in your luggage I wanna go \n",
       "1502254      4            elm8 Thanks  I enjoy talking to you too\n",
       "943392       4  watchin the season finale of The Office lets h...\n",
       "...        ...                                                ...\n",
       "5733         0                           So sleepy this morning  \n",
       "392307       0  bakespace do you archive your newsletters some...\n",
       "1267790      4  santyadh hope that will soon change though  bo...\n",
       "84846        0                   I think I should do my homework \n",
       "580395       0  This is officially the only day since starting...\n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = twitter_df[[\"label\", \"text\"]]\n",
    "twitter_df[\"text\"] = twitter_df[\"text\"].apply(lambda x: clean_text(x))\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.to_csv(\"../datasets/twitter_sampled.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df = pd.read_csv(\"../datasets/twitter_sampled.csv\")\n",
    "twitter_df[\"label\"] = twitter_df[\"label\"].apply(lambda x: \"negative\" if x==0 else \"positive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>why and she screaming ahaha this song is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>negative</td>\n",
       "      <td>the_trini_bajan work as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>desi_f pack me in your luggage I wanna go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>positive</td>\n",
       "      <td>elm8 Thanks  I enjoy talking to you too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>positive</td>\n",
       "      <td>watchin the season finale of The Office lets h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>negative</td>\n",
       "      <td>So sleepy this morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>negative</td>\n",
       "      <td>bakespace do you archive your newsletters some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>positive</td>\n",
       "      <td>santyadh hope that will soon change though  bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>negative</td>\n",
       "      <td>I think I should do my homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>negative</td>\n",
       "      <td>This is officially the only day since starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                               text\n",
       "0     positive    why and she screaming ahaha this song is funny \n",
       "1     negative                     the_trini_bajan work as usual \n",
       "2     negative         desi_f pack me in your luggage I wanna go \n",
       "3     positive            elm8 Thanks  I enjoy talking to you too\n",
       "4     positive  watchin the season finale of The Office lets h...\n",
       "...        ...                                                ...\n",
       "4795  negative                           So sleepy this morning  \n",
       "4796  negative  bakespace do you archive your newsletters some...\n",
       "4797  positive  santyadh hope that will soon change though  bo...\n",
       "4798  negative                   I think I should do my homework \n",
       "4799  negative  This is officially the only day since starting...\n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A female vampire kills young women and paints ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Personally I think this show looks pretty chea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I grew up watching Inspector Gadget It was and...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This movie is awful Im SORRY I bought this to ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is a great example of a good dumb movie N...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>After watching this on the MST3K episode I hav...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>Upon completing this infernal piece of trash a...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>Maybe Im biased because the F16 is my favorite...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>The Best Movie of the 90s The Welsh Trainspott...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>This was a excellent back when it came out It ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text sentiment\n",
       "0     A female vampire kills young women and paints ...  negative\n",
       "1     Personally I think this show looks pretty chea...  negative\n",
       "2     I grew up watching Inspector Gadget It was and...  negative\n",
       "3     This movie is awful Im SORRY I bought this to ...  negative\n",
       "4     This is a great example of a good dumb movie N...  positive\n",
       "...                                                 ...       ...\n",
       "4995  After watching this on the MST3K episode I hav...  negative\n",
       "4996  Upon completing this infernal piece of trash a...  negative\n",
       "4997  Maybe Im biased because the F16 is my favorite...  positive\n",
       "4998  The Best Movie of the 90s The Welsh Trainspott...  negative\n",
       "4999  This was a excellent back when it came out It ...  positive\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df = pd.read_csv(\"../datasets/movies/sampled.csv\")\n",
    "movies_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_twitter_data(train_X, test_X):\n",
    "    train_X[\"label\"] = train_X[\"label\"].apply(lambda x: \"__label__\" + x)\n",
    "    test_X[\"label\"] = test_X[\"label\"].apply(lambda x: \"__label__\" + x)\n",
    "    # Saving the CSV file as a text file to train/test the classifier\n",
    "    train_X[['label', 'text']].to_csv('../datasets/twitter/fasttext_train.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")\n",
    "\n",
    "    test_X[['label', 'text']].to_csv('../datasets/twitter/fasttext_test.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_movies_data(train_X, test_X):\n",
    "    train_X[\"sentiment\"] = train_X[\"sentiment\"].apply(lambda x: \"__label__\" + x)\n",
    "    test_X[\"sentiment\"] = test_X[\"sentiment\"].apply(lambda x: \"__label__\" + x)\n",
    "    # Saving the CSV file as a text file to train/test the classifier\n",
    "    train_X[['sentiment', 'text']].to_csv('../datasets/movies/fasttext_train.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")\n",
    "\n",
    "    test_X[['sentiment', 'text']].to_csv('../datasets/movies/fasttext_test.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(train_X, test_X):\n",
    "    train_X[\"category\"] = train_X[\"category\"].apply(lambda x: \"__label__\" + x)\n",
    "    test_X[\"category\"] = test_X[\"category\"].apply(lambda x: \"__label__\" + x)\n",
    "    # Saving the CSV file as a text file to train/test the classifier\n",
    "    train_X[['category', 'text']].to_csv('../datasets/bbc/fasttext_train.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")\n",
    "\n",
    "    test_X[['category', 'text']].to_csv('../datasets/bbc/fasttext_test.txt', \n",
    "                                            index = False, \n",
    "                                            sep = ' ',\n",
    "                                            header = None, \n",
    "                                            quoting = csv.QUOTE_NONE, \n",
    "                                            quotechar = \"\", \n",
    "                                            escapechar = \" \")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training BBC News Categorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_path, test_path):\n",
    "    model = fasttext.train_supervised(train_path, wordNgrams = 1, epoch = 20, lr=0.4)\n",
    "    n, precision, recall = model.test(test_path)   \n",
    "    f1 = compute_f1(precision, recall)\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  39005\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 2371220 lr:  0.000000 avg.loss:  0.268089 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  39736\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 2146255 lr:  0.000000 avg.loss:  0.334762 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  38895\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 2119361 lr:  0.000000 avg.loss:  0.231247 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  39540\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 2160571 lr:  0.000000 avg.loss:  0.244408 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  39414\n",
      "Number of labels: 5\n",
      "Progress: 100.0% words/sec/thread: 2166931 lr:  0.000000 avg.loss:  0.313807 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "train_path = \"../datasets/bbc/fasttext_train.txt\"\n",
    "test_path = \"../datasets/bbc/fasttext_test.txt\"\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(bbc_df, bbc_df[\"category\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    prepare_data(train_X, test_X)\n",
    "    time.sleep(1)\n",
    "    precision, recall, f1 = train(train_path, test_path)\n",
    "    f1s.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.9730941704035875, 0.9551569506726457, 0.9596412556053812, 0.9596412556053812, 0.9417040358744395]\n",
      "Precision avg: 0.9578 (+/- 0.0225)\n",
      "Recall values: [0.9730941704035875, 0.9551569506726457, 0.9596412556053812, 0.9596412556053812, 0.9417040358744395]\n",
      "Recall avg: 0.9578 (+/- 0.0225)\n",
      "F1 values: [0.9730941704035875, 0.9551569506726457, 0.9596412556053812, 0.9596412556053812, 0.9417040358744395]\n",
      "F1 avg: 0.9578 (+/- 0.0225)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Movies Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  55087\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4132050 lr:  0.000000 avg.loss:  0.152790 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  55509\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4238521 lr:  0.000000 avg.loss:  0.168775 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  55109\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4165218 lr:  0.000000 avg.loss:  0.189808 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  55037\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 4157227 lr:  0.000000 avg.loss:  0.184182 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  55222\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 3558873 lr:  0.000000 avg.loss:  0.178894 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "train_path = \"../datasets/movies/fasttext_train.txt\"\n",
    "test_path = \"../datasets/movies/fasttext_test.txt\"\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(movies_df, movies_df[\"sentiment\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    prepare_movies_data(train_X, test_X)\n",
    "    time.sleep(1)\n",
    "    precision, recall, f1 = train(train_path, test_path)\n",
    "    f1s.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.852, 0.83, 0.838, 0.834, 0.794]\n",
      "Precision avg: 0.8296 (+/- 0.0431)\n",
      "Recall values: [0.852, 0.83, 0.838, 0.834, 0.794]\n",
      "Recall avg: 0.8296 (+/- 0.0431)\n",
      "F1 values: [0.852, 0.83, 0.838, 0.834, 0.7940000000000002]\n",
      "F1 avg: 0.8296 (+/- 0.0431)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training Twitter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Read 0M words\n",
      "Number of words:  11339\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1575134 lr:  0.000000 avg.loss:  0.130671 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  11313\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1542816 lr:  0.000000 avg.loss:  0.158548 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  11389\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1562870 lr:  0.000000 avg.loss:  0.155193 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  11309\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread: 1594767 lr:  0.000000 avg.loss:  0.091563 ETA:   0h 0m 0s\n",
      "Read 0M words\n",
      "Number of words:  11375\n",
      "Number of labels: 2\n",
      "Progress: 100.0% words/sec/thread:  793853 lr:  0.000000 avg.loss:  0.115710 ETA:   0h 0m 0s\n"
     ]
    }
   ],
   "source": [
    "f1s = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "train_path = \"../datasets/twitter/fasttext_train.txt\"\n",
    "test_path = \"../datasets/twitter/fasttext_test.txt\"\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(twitter_df, twitter_df[\"label\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    prepare_twitter_data(train_X, test_X)\n",
    "    time.sleep(1)\n",
    "    precision, recall, f1 = train(train_path, test_path)\n",
    "    f1s.append(f1)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.7333333333333333, 0.6770833333333334, 0.6979166666666666, 0.6958333333333333, 0.69375]\n",
      "Precision avg: 0.6996 (+/- 0.0412)\n",
      "Recall values: [0.7333333333333333, 0.6770833333333334, 0.6979166666666666, 0.6958333333333333, 0.69375]\n",
      "Recall avg: 0.6996 (+/- 0.0412)\n",
      "F1 values: [0.7333333333333333, 0.6770833333333334, 0.6979166666666666, 0.6958333333333333, 0.69375]\n",
      "F1 avg: 0.6996 (+/- 0.0412)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd4a2e0defd57de5fbee3712486c1f066f8e1e168ee0000614ffba8faf61667"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
