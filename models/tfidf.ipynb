{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import statistics\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_VAL_SIZE = 0.2\n",
    "VAL_TEST_SIZE = 0.5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(true_labels, predictions):\n",
    "  f1 = f1_score(true_labels, predictions, average=\"macro\")\n",
    "  precision = precision_score(true_labels, predictions, average=\"macro\")\n",
    "  recall = recall_score(true_labels, predictions, average=\"macro\")\n",
    "  accuracy = accuracy_score(true_labels,predictions)\n",
    "  return f1, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rayenebech/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rayenebech/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_df = pd.read_csv(\"../datasets/bbc/bbc-text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sport            511\n",
       "business         510\n",
       "politics         417\n",
       "tech             401\n",
       "entertainment    386\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bbc_df[\"category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"../datasets/movies/sampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    2520\n",
       "positive    2480\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>why and she screaming ahaha this song is funny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>the_trini_bajan work as usual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>desi_f pack me in your luggage I wanna go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>elm8 Thanks  I enjoy talking to you too</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>watchin the season finale of The Office lets h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4795</th>\n",
       "      <td>0</td>\n",
       "      <td>So sleepy this morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4796</th>\n",
       "      <td>0</td>\n",
       "      <td>bakespace do you archive your newsletters some...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4797</th>\n",
       "      <td>4</td>\n",
       "      <td>santyadh hope that will soon change though  bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>0</td>\n",
       "      <td>I think I should do my homework</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4799</th>\n",
       "      <td>0</td>\n",
       "      <td>This is officially the only day since starting...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4800 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0         4    why and she screaming ahaha this song is funny \n",
       "1         0                     the_trini_bajan work as usual \n",
       "2         0         desi_f pack me in your luggage I wanna go \n",
       "3         4            elm8 Thanks  I enjoy talking to you too\n",
       "4         4  watchin the season finale of The Office lets h...\n",
       "...     ...                                                ...\n",
       "4795      0                           So sleepy this morning  \n",
       "4796      0  bakespace do you archive your newsletters some...\n",
       "4797      4  santyadh hope that will soon change though  bo...\n",
       "4798      0                   I think I should do my homework \n",
       "4799      0  This is officially the only day since starting...\n",
       "\n",
       "[4800 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df = pd.read_csv(\"../datasets/twitter_sampled.csv\")\n",
    "twitter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2409\n",
       "4    2391\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_df[\"label\"].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model with 5 Kfolds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_X, train_Y, test_X, test_Y):\n",
    "    tf_idf = TfidfVectorizer()\n",
    "    classifier_tfidf = LogisticRegression()\n",
    "\n",
    "    # Train\n",
    "    model_tfidf = Pipeline([(\"vectorizer\", tf_idf), (\"classifier\", classifier_tfidf)])\n",
    "    start_time = datetime.now()\n",
    "    model_tfidf.fit(train_X[\"text\"], train_Y)\n",
    "    end_time = datetime.now()\n",
    "    training_time_tfidf = (end_time - start_time).total_seconds()\n",
    "\n",
    "    # Eval    \n",
    "    predicted_test_tfidf = model_tfidf.predict(test_X[\"text\"])\n",
    "    test_f1, test_precision, test_recall, test_accuracy = get_metrics(predicted_test_tfidf, test_Y)\n",
    "    print('Testing: Accuracy: {:.3%}, Recall: {:.3%}, Precision: {:.3%}, f1: {:.3%}'.format(test_accuracy,test_recall, test_precision, test_f1))\n",
    "    print('Training time: {:.2f}s'.format(training_time_tfidf))\n",
    "    return test_precision, test_recall, test_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 97.309%, Recall: 97.418%, Precision: 97.249%, f1: 97.310%\n",
      "Training time: 1.18s\n",
      "Testing: Accuracy: 98.206%, Recall: 98.429%, Precision: 97.936%, f1: 98.151%\n",
      "Training time: 1.16s\n",
      "Testing: Accuracy: 95.964%, Recall: 96.249%, Precision: 96.250%, f1: 96.189%\n",
      "Training time: 1.18s\n",
      "Testing: Accuracy: 97.309%, Recall: 97.384%, Precision: 97.292%, f1: 97.308%\n",
      "Training time: 1.23s\n",
      "Testing: Accuracy: 96.413%, Recall: 96.828%, Precision: 96.551%, f1: 96.684%\n",
      "Training time: 1.24s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(bbc_df, bbc_df[\"category\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.9724888668975755, 0.9793615494978478, 0.9625042999656003, 0.972916611603013, 0.9655129958960329]\n",
      "Precision avg: 0.9706 (+/- 0.0133)\n",
      "Recall values: [0.9741835758693721, 0.9842857142857142, 0.9624888445049754, 0.9738412698412698, 0.9682805947388486]\n",
      "Recall avg: 0.9726 (+/- 0.0162)\n",
      "F1 values: [0.9731015774730946, 0.981510338217171, 0.9618899664187301, 0.9730829815634836, 0.9668400262764593]\n",
      "F1 avg: 0.9713 (+/- 0.0148)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Movies datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 83.600%, Recall: 83.635%, Precision: 83.532%, f1: 83.562%\n",
      "Training time: 1.13s\n",
      "Testing: Accuracy: 83.000%, Recall: 83.133%, Precision: 82.870%, f1: 82.926%\n",
      "Training time: 1.33s\n",
      "Testing: Accuracy: 83.600%, Recall: 83.535%, Precision: 83.565%, f1: 83.548%\n",
      "Training time: 1.21s\n",
      "Testing: Accuracy: 85.800%, Recall: 85.883%, Precision: 85.750%, f1: 85.775%\n",
      "Training time: 1.38s\n",
      "Testing: Accuracy: 86.800%, Recall: 86.876%, Precision: 86.860%, f1: 86.800%\n",
      "Training time: 1.33s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(movies_df, movies_df[\"sentiment\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.8353193670318406, 0.8286979925984075, 0.8356483340024087, 0.8575030012004802, 0.8685963114754098]\n",
      "Precision avg: 0.8452 (+/- 0.0341)\n",
      "Recall values: [0.8363537047747573, 0.8313254957690072, 0.8353467776868653, 0.8588297667245035, 0.8687616118905759]\n",
      "Recall avg: 0.8461 (+/- 0.0332)\n",
      "F1 values: [0.8356212714093271, 0.8292562401822339, 0.8354840780688239, 0.8577490693583482, 0.8679978879662074]\n",
      "F1 avg: 0.8452 (+/- 0.0334)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train with Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: Accuracy: 74.583%, Recall: 74.607%, Precision: 74.600%, f1: 74.583%\n",
      "Training time: 0.08s\n",
      "Testing: Accuracy: 73.750%, Recall: 73.728%, Precision: 73.728%, f1: 73.728%\n",
      "Training time: 0.19s\n",
      "Testing: Accuracy: 72.292%, Recall: 72.535%, Precision: 72.388%, f1: 72.265%\n",
      "Training time: 0.12s\n",
      "Testing: Accuracy: 71.042%, Recall: 71.100%, Precision: 71.176%, f1: 71.026%\n",
      "Training time: 0.10s\n",
      "Testing: Accuracy: 71.667%, Recall: 71.667%, Precision: 71.664%, f1: 71.665%\n",
      "Training time: 0.09s\n"
     ]
    }
   ],
   "source": [
    "precisions = []\n",
    "recalls = []\n",
    "f1s = []\n",
    "for i in range(5):\n",
    "    train_X, val_X, train_Y, val_Y = train_test_split(twitter_df, twitter_df[\"label\"], test_size = TRAIN_VAL_SIZE)\n",
    "    val_X, test_X, val_Y, test_Y = train_test_split(val_X, val_Y, test_size = VAL_TEST_SIZE)\n",
    "    precision, recall, f1 = train(train_X, train_Y, test_X, test_Y)\n",
    "    precisions.append(precision)\n",
    "    recalls.append(recall)\n",
    "    f1s.append(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision values: [0.7460019794759598, 0.7372765025803201, 0.723881893182805, 0.7117647058823529, 0.7166443861872602]\n",
      "Precision avg: 0.7271 (+/- 0.0286)\n",
      "Recall values: [0.7460703430308293, 0.7372765025803201, 0.7253496503496504, 0.7109961100305641, 0.7166744803875605]\n",
      "Recall avg: 0.7273 (+/- 0.0289)\n",
      "F1 values: [0.7458289206409834, 0.7372765025803201, 0.7226458129683936, 0.7102645052306116, 0.7166469893742621]\n",
      "F1 avg: 0.7265 (+/- 0.0294)\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision values:\", precisions)\n",
    "print(\"Precision avg: %0.4f (+/- %0.4f)\" % (statistics.mean(precisions), statistics.stdev(precisions) * 2))\n",
    "print(\"Recall values:\", recalls)\n",
    "print(\"Recall avg: %0.4f (+/- %0.4f)\" % (statistics.mean(recalls), statistics.stdev(recalls) * 2))\n",
    "print(\"F1 values:\", f1s)\n",
    "print(\"F1 avg: %0.4f (+/- %0.4f)\" % (statistics.mean(f1s), statistics.stdev(f1s) * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9 (default, Apr 13 2022, 08:48:06) \n[Clang 13.1.6 (clang-1316.0.21.2.5)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd4a2e0defd57de5fbee3712486c1f066f8e1e168ee0000614ffba8faf61667"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
